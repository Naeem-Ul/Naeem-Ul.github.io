{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naeem-Ul/Naeem-Ul.github.io/blob/master/AD_detection_RCNN_96__(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ldYEBc4tm3xA",
        "outputId": "07d6c761-f676-41fa-d048-28946522d52d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text==2.8.*\n",
            "  Downloading tensorflow_text-2.8.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text==2.8.*) (0.16.1)\n",
            "Collecting tensorflow<2.9,>=2.8.0 (from tensorflow-text==2.8.*)\n",
            "  Downloading tensorflow-2.8.4-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (24.12.23)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.12.1)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.4.0)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.17.0)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting tensorflow-estimator<2.9,>=2.8 (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.9,>=2.8.0rc0 (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.69.0)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.8.0->tensorflow-text==2.8.*) (2.17.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.32.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.1.3)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow-hub>=0.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.2.2)\n",
            "Downloading tensorflow_text-2.8.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.8.4-cp310-cp310-manylinux2010_x86_64.whl (498.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-estimator, tensorboard-plugin-wit, keras, tf-keras, tensorboard-data-server, protobuf, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-aiplatform 1.74.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.27.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigtable 2.27.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-firestore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-functions 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.27.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "googleapis-common-protos 1.66.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.19.6 which is incompatible.\n",
            "pandas-gbq 0.26.1 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.7 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.4 tensorflow-estimator-2.8.0 tensorflow-text-2.8.2 tf-keras-2.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "bea48b2ba5f846918c17969e913ef4bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'augmented_dementiabank.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-74f774cc3c09>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'augmented_dementiabank.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'augmented_dementiabank.csv'"
          ]
        }
      ],
      "source": [
        "!pip install \"tensorflow-text==2.8.*\"\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "!pip install transformers\n",
        "\n",
        "#loading data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.read_csv('augmented_dementiabank.csv',encoding ='latin-1',names=('target','Text'))\n",
        "df.head(5)\n",
        "df['target'].value_counts()\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Text'],df['target'])\n",
        "#X_train, X_test, y_train, y_test = train_test_split(df.drop('Text', axis=1), df['target'], test_size=0.3, random_state=0)\n",
        "\n",
        "import numpy as np\n",
        "np.savez('X_train.npz',X_train)\n",
        "np.savez('X_test.npz',X_test)\n",
        "np.savez('y_train.npz',y_train)\n",
        "np.savez('y_test.npz',y_test)\n",
        "X_train=np.load('X_train.npz',allow_pickle=True)\n",
        "print(X_train['arr_0'].shape)\n",
        "print(X_train['arr_0'])\n",
        "X_train = np.load('X_train.npz', allow_pickle=True)['arr_0']\n",
        "y_train = np.load('y_train.npz', allow_pickle=True)['arr_0']\n",
        "X_test = np.load('X_test.npz', allow_pickle=True)['arr_0']\n",
        "y_test = np.load('y_test.npz', allow_pickle=True)['arr_0']\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Input layers\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "\n",
        "# Preprocessing layers\n",
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "\n",
        "# BERT encoder layer\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
        "bert_outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "# Convolutional layer\n",
        "conv_layer = tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu')(bert_outputs['sequence_output'])\n",
        "\n",
        "# Recurrent layer\n",
        "recurrent_layer = tf.keras.layers.LSTM(64, return_sequences=True)(conv_layer)\n",
        "\n",
        "# Pooling layer\n",
        "pooling_layer = tf.keras.layers.GlobalMaxPooling1D()(recurrent_layer)\n",
        "\n",
        "# Dense layers\n",
        "dense_layer = tf.keras.layers.Dense(128, activation='relu')(pooling_layer)\n",
        "dense_layer = tf.keras.layers.Dense(128, activation='relu')(pooling_layer)\n",
        "dense_layer = tf.keras.layers.Dense(128, activation='relu')(pooling_layer)\n",
        "output_layer = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(dense_layer)\n",
        "\n",
        "# Construct the final model\n",
        "model = tf.keras.Model(inputs=text_input, outputs=output_layer)\n",
        "\n",
        "'''bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
        "## Bert layers\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "# Neural network layers\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "l = tf.keras.layers.Dense(64, activation='relu')(l)\n",
        "#l = tf.keras.layers.Flatten()(l)  # Use tf.keras.layers.Flatten() instead of Flatten()\n",
        "#l = tf.keras.layers.Dense(3, activation='softmax')(l)  # Add missing Dense layer\n",
        "l = tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(l)\n",
        "l = tf.keras.layers.Dense(128, activation='relu')(l)\n",
        "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "# Use inputs and outputs to construct a final model\n",
        "model = tf.keras.Model(inputs=[text_input], outputs = [l])\n",
        "model.summary()'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5PvzEqpGOiW",
        "outputId": "e370722e-48fc-4658-e3bf-f248ccfcc910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)       {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " keras_layer_1 (KerasLayer)     {'sequence_output':  109482241   ['keras_layer[0][0]',            \n",
            "                                 (None, 128, 768),                'keras_layer[0][1]',            \n",
            "                                 'default': (None,                'keras_layer[0][2]']            \n",
            "                                768),                                                             \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 126, 64)      147520      ['keras_layer_1[0][14]']         \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 126, 64)      33024       ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 64)          0           ['lstm[0][0]']                   \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          8320        ['global_max_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 1)            129         ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,671,234\n",
            "Trainable params: 188,993\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=2)\n",
        "\n",
        "model.compile(optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=METRICS)\n",
        "checkpoint_path = \"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "cp = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1, mode='max')\n",
        "csv_logger = tf.keras.callbacks.CSVLogger('logfile.log')\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=2)\n",
        "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=1, min_lr=0.00001)"
      ],
      "metadata": {
        "id": "j_HdMelue3ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test,y_test),callbacks=[cp, csv_logger,reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_8elwQbe6TX",
        "outputId": "2bcd4176-8d1b-4c19-fea4-bcb077800685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6232 - accuracy: 0.6625 - precision: 0.6592 - recall: 0.7163\n",
            "Epoch 1: val_accuracy improved from -inf to 0.79144, saving model to weights-improvement-01-0.79.hdf5\n",
            "35/35 [==============================] - 45s 713ms/step - loss: 0.6232 - accuracy: 0.6625 - precision: 0.6592 - recall: 0.7163 - val_loss: 0.4809 - val_accuracy: 0.7914 - val_precision: 0.8544 - val_recall: 0.7105 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4245 - accuracy: 0.8107 - precision: 0.8211 - recall: 0.8097\n",
            "Epoch 2: val_accuracy improved from 0.79144 to 0.80749, saving model to weights-improvement-02-0.81.hdf5\n",
            "35/35 [==============================] - 18s 512ms/step - loss: 0.4245 - accuracy: 0.8107 - precision: 0.8211 - recall: 0.8097 - val_loss: 0.4003 - val_accuracy: 0.8075 - val_precision: 0.8315 - val_recall: 0.7789 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3411 - accuracy: 0.8455 - precision: 0.8702 - recall: 0.8235\n",
            "Epoch 3: val_accuracy did not improve from 0.80749\n",
            "35/35 [==============================] - 17s 488ms/step - loss: 0.3411 - accuracy: 0.8455 - precision: 0.8702 - recall: 0.8235 - val_loss: 0.4377 - val_accuracy: 0.7941 - val_precision: 0.9449 - val_recall: 0.6316 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.8884 - precision: 0.9096 - recall: 0.8702\n",
            "Epoch 4: val_accuracy improved from 0.80749 to 0.82888, saving model to weights-improvement-04-0.83.hdf5\n",
            "35/35 [==============================] - 19s 542ms/step - loss: 0.2772 - accuracy: 0.8884 - precision: 0.9096 - recall: 0.8702 - val_loss: 0.3948 - val_accuracy: 0.8289 - val_precision: 0.7739 - val_recall: 0.9368 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1894 - accuracy: 0.9321 - precision: 0.9358 - recall: 0.9325\n",
            "Epoch 5: val_accuracy improved from 0.82888 to 0.84492, saving model to weights-improvement-05-0.84.hdf5\n",
            "35/35 [==============================] - 19s 534ms/step - loss: 0.1894 - accuracy: 0.9321 - precision: 0.9358 - recall: 0.9325 - val_loss: 0.3596 - val_accuracy: 0.8449 - val_precision: 0.9648 - val_recall: 0.7211 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.9580 - precision: 0.9683 - recall: 0.9498\n",
            "Epoch 6: val_accuracy improved from 0.84492 to 0.90909, saving model to weights-improvement-06-0.91.hdf5\n",
            "35/35 [==============================] - 18s 521ms/step - loss: 0.1192 - accuracy: 0.9580 - precision: 0.9683 - recall: 0.9498 - val_loss: 0.2383 - val_accuracy: 0.9091 - val_precision: 0.9286 - val_recall: 0.8895 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9875 - precision: 0.9896 - recall: 0.9862\n",
            "Epoch 7: val_accuracy improved from 0.90909 to 0.93850, saving model to weights-improvement-07-0.94.hdf5\n",
            "35/35 [==============================] - 18s 519ms/step - loss: 0.0525 - accuracy: 0.9875 - precision: 0.9896 - recall: 0.9862 - val_loss: 0.1963 - val_accuracy: 0.9385 - val_precision: 0.9418 - val_recall: 0.9368 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9973 - precision: 0.9983 - recall: 0.9965\n",
            "Epoch 8: val_accuracy did not improve from 0.93850\n",
            "35/35 [==============================] - 17s 485ms/step - loss: 0.0235 - accuracy: 0.9973 - precision: 0.9983 - recall: 0.9965 - val_loss: 0.1831 - val_accuracy: 0.9278 - val_precision: 0.9095 - val_recall: 0.9526 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9982 - precision: 0.9983 - recall: 0.9983\n",
            "Epoch 9: val_accuracy did not improve from 0.93850\n",
            "35/35 [==============================] - 17s 486ms/step - loss: 0.0155 - accuracy: 0.9982 - precision: 0.9983 - recall: 0.9983 - val_loss: 0.2105 - val_accuracy: 0.9358 - val_precision: 0.9882 - val_recall: 0.8842 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9982 - precision: 0.9983 - recall: 0.9983\n",
            "Epoch 10: val_accuracy improved from 0.93850 to 0.94385, saving model to weights-improvement-10-0.94.hdf5\n",
            "35/35 [==============================] - 18s 525ms/step - loss: 0.0091 - accuracy: 0.9982 - precision: 0.9983 - recall: 0.9983 - val_loss: 0.1682 - val_accuracy: 0.9439 - val_precision: 0.9378 - val_recall: 0.9526 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 11: val_accuracy improved from 0.94385 to 0.95722, saving model to weights-improvement-11-0.96.hdf5\n",
            "35/35 [==============================] - 18s 528ms/step - loss: 0.0040 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9572 - val_precision: 0.9677 - val_recall: 0.9474 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 486ms/step - loss: 0.0017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9572 - val_precision: 0.9677 - val_recall: 0.9474 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 491ms/step - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9519 - val_precision: 0.9574 - val_recall: 0.9474 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.7028e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 492ms/step - loss: 9.7028e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.4883e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 489ms/step - loss: 9.4883e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.3207e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 18s 503ms/step - loss: 9.3207e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.3047e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 19s 533ms/step - loss: 9.3047e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2846e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 494ms/step - loss: 9.2846e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-06\n",
            "Epoch 19/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2823e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 492ms/step - loss: 9.2823e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-06\n",
            "Epoch 20/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2807e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 489ms/step - loss: 9.2807e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-07\n",
            "Epoch 21/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2806e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 485ms/step - loss: 9.2806e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-07\n",
            "Epoch 22/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 483ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-08\n",
            "Epoch 23/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 489ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-08\n",
            "Epoch 24/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 490ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-09\n",
            "Epoch 25/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-09\n",
            "Epoch 26/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 490ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-10\n",
            "Epoch 27/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 488ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-10\n",
            "Epoch 28/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-11\n",
            "Epoch 29/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 498ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-11\n",
            "Epoch 30/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 18s 517ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-12\n",
            "Epoch 31/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 490ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-12\n",
            "Epoch 32/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 491ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-13\n",
            "Epoch 33/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 491ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-13\n",
            "Epoch 34/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 488ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-14\n",
            "Epoch 35/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-14\n",
            "Epoch 36/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 489ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-15\n",
            "Epoch 37/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 486ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-15\n",
            "Epoch 38/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 485ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-16\n",
            "Epoch 39/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-16\n",
            "Epoch 40/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 489ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-17\n",
            "Epoch 41/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 490ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-17\n",
            "Epoch 42/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 485ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-18\n",
            "Epoch 43/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 486ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-18\n",
            "Epoch 44/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 484ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-19\n",
            "Epoch 45/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 484ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-19\n",
            "Epoch 46/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 488ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-20\n",
            "Epoch 47/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 486ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-20\n",
            "Epoch 48/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 482ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-21\n",
            "Epoch 49/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 484ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-21\n",
            "Epoch 50/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-22\n",
            "Epoch 51/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 51: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 485ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-22\n",
            "Epoch 52/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 52: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 486ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-23\n",
            "Epoch 53/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 53: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 486ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-23\n",
            "Epoch 54/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 54: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-24\n",
            "Epoch 55/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 55: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 489ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-24\n",
            "Epoch 56/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 56: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 485ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-25\n",
            "Epoch 57/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 57: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 486ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-25\n",
            "Epoch 58/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 58: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 488ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-26\n",
            "Epoch 59/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 59: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 484ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-26\n",
            "Epoch 60/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 60: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 485ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-27\n",
            "Epoch 61/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 61: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 485ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-27\n",
            "Epoch 62/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 62: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 485ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-28\n",
            "Epoch 63/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 63: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 484ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-28\n",
            "Epoch 64/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 64: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 492ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-29\n",
            "Epoch 65/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 65: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 485ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-29\n",
            "Epoch 66/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 66: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 485ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-30\n",
            "Epoch 67/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 67: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 490ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-30\n",
            "Epoch 68/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 68: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 18s 518ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-31\n",
            "Epoch 69/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 69: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 497ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-31\n",
            "Epoch 70/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 70: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 490ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-32\n",
            "Epoch 71/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 71: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 488ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-32\n",
            "Epoch 72/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 72: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 486ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-33\n",
            "Epoch 73/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 73: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-33\n",
            "Epoch 74/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 74: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 488ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-34\n",
            "Epoch 75/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 75: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-34\n",
            "Epoch 76/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 76: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-35\n",
            "Epoch 77/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 77: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-35\n",
            "Epoch 78/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 78: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-36\n",
            "Epoch 79/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 79: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 489ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-36\n",
            "Epoch 80/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 80: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 489ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-37\n",
            "Epoch 81/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 81: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 492ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-37\n",
            "Epoch 82/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 82: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 489ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-38\n",
            "Epoch 83/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 83: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 486ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-38\n",
            "Epoch 84/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 84: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 492ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-39\n",
            "Epoch 85/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 85: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 489ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0000e-39\n",
            "Epoch 86/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 86: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 486ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 9.9999e-41\n",
            "Epoch 87/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 87: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 9.9999e-41\n",
            "Epoch 88/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 88: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 486ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 9.9997e-42\n",
            "Epoch 89/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 89: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 9.9997e-42\n",
            "Epoch 90/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 90: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0005e-42\n",
            "Epoch 91/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 91: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 489ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.0005e-42\n",
            "Epoch 92/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 92: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 9.9492e-44\n",
            "Epoch 93/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 93: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 487ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 9.9492e-44\n",
            "Epoch 94/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 94: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 488ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 9.8091e-45\n",
            "Epoch 95/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 95: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 486ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 9.8091e-45\n",
            "Epoch 96/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 96: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 488ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.4013e-45\n",
            "Epoch 97/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 97: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 490ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 1.4013e-45\n",
            "Epoch 98/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 98: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 490ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 0.0000e+00\n",
            "Epoch 99/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 99: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 491ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 0.0000e+00\n",
            "Epoch 100/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 100: val_accuracy did not improve from 0.95722\n",
            "35/35 [==============================] - 17s 490ms/step - loss: 9.2804e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9545 - val_precision: 0.9626 - val_recall: 0.9474 - lr: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcca6574a60>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict(X_test)\n",
        "y_predicted = y_predicted.flatten()"
      ],
      "metadata": {
        "id": "yd7VIdYGQnRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_predicted= np.where(y_predicted > 0.5, 1, 0)\n",
        "print(y_predicted)\n",
        "accuracy = accuracy_score(y_test, y_predicted)\n",
        "print(f\"Accuracy score: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TVZhkHlQqBR",
        "outputId": "379c441e-9e05-4f1a-8929-80eb5697090a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0\n",
            " 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1\n",
            " 1 0 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1\n",
            " 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 1\n",
            " 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1\n",
            " 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1\n",
            " 1 1 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1\n",
            " 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0\n",
            " 0 0 0 1 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 0 1 0\n",
            " 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1\n",
            " 1 0 1 1]\n",
            "Accuracy score: 0.9545454545454546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_dataset = [\n",
        "\" the scene is in the in the kitchen . the mother is wiping dishes and the water is running on the floor . a child is trying to get a boy is trying to get cookies outta out a jar and he's about to tip over on a stool . the little girl is reacting to his falling . it seems to be summer out . the window is open . the curtains are blowing . it must be a gentle breeze . there's grass outside in the garden . mother's finished certain of the the dishes . kitchen's very tidy . the mother seems to have nothing in the house to eat except cookies in the cookie jar . the children look to be almost about the same size . perhaps they're twins . they're dressed for summer warm weather . you want more ? the mother's in a short sleeve dress . I'll hafta say it's warm . \" ,\n",
        "                   \"  it's kinda shiny there . I   okay it looks like somebody's raiding the cookie jar .  there's a woman  working in the kitchen .  and there's this little girl here with something but I don't know what it is she yeah I'm trying to identify this thing . d?d?ku trying to see . is that a table leg ?  I'd say that's a table leg . \",\n",
        "                  \"the little boy is reaching for a cookie . and he's falling at the same time because the stool has tipped over . his little sister is reaching for a cookie and I think beginning to laugh because he's falling . the sink is running over and dripping water on the floor while the mother is trying to dry the dishes . the window is open and the curtains are blowing in the breeze coming in from outside . the water is running in the sink . that's why it's overflowing .  I also believe that the mother is daydreaming .  possibly worrying about something . that's it . that's all I see . \" ]\n",
        "model.predict(sample_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "JlUNAUfiQsYp",
        "outputId": "07cb34d1-0128-4f10-aa17-ffc5fbef3d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-21cff9a5c6a1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                    \u001b[0;34m\"  it's kinda shiny there . I   okay it looks like somebody's raiding the cookie jar .  there's a woman  working in the kitchen .  and there's this little girl here with something but I don't know what it is she yeah I'm trying to identify this thing . d?d?ku trying to see . is that a table leg ?  I'd say that's a table leg . \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \"the little boy is reaching for a cookie . and he's falling at the same time because the stool has tipped over . his little sister is reaching for a cookie and I think beginning to laugh because he's falling . the sink is running over and dripping water on the floor while the mother is trying to dry the dishes . the window is open and the curtains are blowing in the breeze coming in from outside . the water is running in the sink . that's why it's overflowing .  I also believe that the mother is daydreaming .  possibly worrying about something . that's it . that's all I see . \" ]\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}