{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naeem-Ul/Naeem-Ul.github.io/blob/master/Ensembleall_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uhHXuhiHkUIV",
        "outputId": "77ca72ad-dcf8-4496-f680-ec68ebcc2e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text==2.8.*\n",
            "  Downloading tensorflow_text-2.8.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/4.9 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m3.7/4.9 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text==2.8.*) (0.13.0)\n",
            "Collecting tensorflow<2.9,>=2.8.0 (from tensorflow-text==2.8.*)\n",
            "  Downloading tensorflow-2.8.4-cp310-cp310-manylinux2010_x86_64.whl (498.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (23.5.26)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.8.0)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (16.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.0)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.14.1)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.9,>=2.8 (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0 (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.32.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.56.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.17.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.27.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard-plugin-wit, keras, tensorboard-data-server, protobuf, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.1\n",
            "    Uninstalling tensorboard-data-server-0.7.1:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.4 tensorflow-estimator-2.8.0 tensorflow-text-2.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ],
      "source": [
        "!pip install \"tensorflow-text==2.8.*\"\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "!pip install transformers\n",
        "#loading data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.read_csv('augmented_dementiabank.csv',encoding ='latin-1',names=('target','text'))\n",
        "df.head(5)\n",
        "df['target'].value_counts()\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'],df['target'], test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laDIo3BFksP2",
        "outputId": "a8f52a5d-f95d-4256-d5fd-573db708ce60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1195,)\n",
            "[\" well te kd the girl's laughing at her brother because he went into the cookie jar nd he's falling over the cookie jar . and mother's the mother was t the sink . and the sink's splashing splashing over the sink . and she sortof a little bt bitchy . and the water' going flooding over the sink . and there's a saucer, there's a plate, there's a couple of dishes . ell she's and the mother's looking out the window . she don't knw hat the hell to think of it . a girl laughing at her rother who is taking cookies outof the cokie jar and he's ready to fall off the damn off the off the chair he's on . the chair's crooked . what the hell else ? nd he there's a plate, saucer and two cups . she's looking out the window . the window's open . she's not paying any attention o the kids . the water's flooding over the sink . what else you want ? \"\n",
            " \" oh I see the sink is running over . and I see the stool is tipping ove . the little boy i trying to get cookies out . the little girl is  reaching to get a cookie . the mother s drying dishes . the window's open . did I say did I say she's washing ? oh she's drying dishes now . that's going up . and she's standing in the water .  I think the cupboard dor is open . and thee's a cookie jar . the lid is leaning against te cookie j . this is curtains on te window . I can see the grass and some shrubbery outside and the house next door . kitchen cabinets .  is that it ?  they'll I see thre peope in tere, a mother and little boy and a girl . \"\n",
            " \" well the chair's gonna upset . and the kid's  gonna upset the cookies for one thing . and the woman te sink's running over the water on the floor while she's drying the dishes .  and you eed aer in there to wash the dishes and i's running on the floor . you can look out the window and see the grass . \"\n",
            " ...\n",
            " \"  well the mother's doing the dishes and allowing the sink to rn run over . the kids or the bo's in the cookie jar . and the stand that he's standing on is tilting over . and I don't kno what the irl is doing . gonna tell on hm or do something . and then there's some people out hee behind the garage . I don't know what they are doing . d you see them ? \"\n",
            " \" you're washing the she se's washing the dishes . and his stool is tilting . and he gonna and he jars . cookie jar . and the wter's overflowing on the floo .  he handing th girl girl the cookies .  she's drying the dishes .  there's a cup and saucer on the and plate o the counter . hmhunh . \"\n",
            " \" these two little kid are getting cookies outf the cookie jar . and and this lady over here is what is she doing ? she's decorating . isn't that what she's doing ? decorating ? well, they'r getting cookies otta out the cookie jar . up on a stool that looks like it's gonna topple over . looks like she's washing dishes . drying dishes . she's got a cloth in her hand ad a dish in her hand . and the oh, maybe shes gonna wpe up some water because it's sure running out  here f the sink . \"]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.savez('X_train.npz',X_train)\n",
        "np.savez('X_test.npz',X_test)\n",
        "np.savez('y_train.npz',y_train)\n",
        "np.savez('y_test.npz',y_test)\n",
        "X_train=np.load('X_train.npz',allow_pickle=True)\n",
        "print(X_train['arr_0'].shape)\n",
        "print(X_train['arr_0'])\n",
        "X_train = np.load('X_train.npz', allow_pickle=True)['arr_0']\n",
        "y_train = np.load('y_train.npz', allow_pickle=True)['arr_0']\n",
        "X_test = np.load('X_test.npz', allow_pickle=True)['arr_0']\n",
        "y_test = np.load('y_test.npz', allow_pickle=True)['arr_0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi9hzACckyTc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ4zlR5zk10n"
      },
      "outputs": [],
      "source": [
        "## Bert layers\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztq07D7Lk12x"
      },
      "outputs": [],
      "source": [
        "bert_outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "# Convolutional layer\n",
        "conv_layer = tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu')(bert_outputs['sequence_output'])\n",
        "\n",
        "# Recurrent layer\n",
        "recurrent_layer = tf.keras.layers.LSTM(64, return_sequences=True)(conv_layer)\n",
        "\n",
        "# Pooling layer\n",
        "pooling_layer = tf.keras.layers.GlobalMaxPooling1D()(recurrent_layer)\n",
        "\n",
        "# Dense layers\n",
        "dense_layer = tf.keras.layers.Dense(128, activation='relu')(pooling_layer)\n",
        "dense_layer = tf.keras.layers.Dense(128, activation='relu')(pooling_layer)\n",
        "dense_layer = tf.keras.layers.Dense(128, activation='relu')(pooling_layer)\n",
        "output_layer = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(dense_layer)\n",
        "\n",
        "# Construct the final model\n",
        "model = tf.keras.Model(inputs=text_input, outputs=output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xjcAVO-k145",
        "outputId": "a3cba4eb-b642-40fe-e095-e70ac08cfd88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5861 - accuracy: 0.6854 - precision: 0.6667 - recall: 0.7772\n",
            "Epoch 1: val_accuracy improved from -inf to 0.77258, saving model to weights-improvement-01-0.77.hdf5\n",
            "38/38 [==============================] - 48s 559ms/step - loss: 0.5861 - accuracy: 0.6854 - precision: 0.6667 - recall: 0.7772 - val_loss: 0.4966 - val_accuracy: 0.7726 - val_precision: 0.8761 - val_recall: 0.6471 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.8243 - precision: 0.8610 - recall: 0.7854\n",
            "Epoch 2: val_accuracy did not improve from 0.77258\n",
            "38/38 [==============================] - 17s 451ms/step - loss: 0.3982 - accuracy: 0.8243 - precision: 0.8610 - recall: 0.7854 - val_loss: 0.6194 - val_accuracy: 0.6355 - val_precision: 0.5894 - val_recall: 0.9477 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.8510 - precision: 0.8600 - recall: 0.8488\n",
            "Epoch 3: val_accuracy improved from 0.77258 to 0.85953, saving model to weights-improvement-03-0.86.hdf5\n",
            "38/38 [==============================] - 19s 498ms/step - loss: 0.3476 - accuracy: 0.8510 - precision: 0.8600 - recall: 0.8488 - val_loss: 0.3568 - val_accuracy: 0.8595 - val_precision: 0.8881 - val_recall: 0.8301 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.8828 - precision: 0.8900 - recall: 0.8813\n",
            "Epoch 4: val_accuracy did not improve from 0.85953\n",
            "38/38 [==============================] - 18s 476ms/step - loss: 0.2779 - accuracy: 0.8828 - precision: 0.8900 - recall: 0.8813 - val_loss: 0.3301 - val_accuracy: 0.8462 - val_precision: 0.8690 - val_recall: 0.8235 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.9297 - precision: 0.9462 - recall: 0.9154\n",
            "Epoch 5: val_accuracy improved from 0.85953 to 0.88294, saving model to weights-improvement-05-0.88.hdf5\n",
            "38/38 [==============================] - 24s 631ms/step - loss: 0.1837 - accuracy: 0.9297 - precision: 0.9462 - recall: 0.9154 - val_loss: 0.2618 - val_accuracy: 0.8829 - val_precision: 0.9275 - val_recall: 0.8366 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1257 - accuracy: 0.9548 - precision: 0.9621 - recall: 0.9496\n",
            "Epoch 6: val_accuracy improved from 0.88294 to 0.90301, saving model to weights-improvement-06-0.90.hdf5\n",
            "38/38 [==============================] - 19s 498ms/step - loss: 0.1257 - accuracy: 0.9548 - precision: 0.9621 - recall: 0.9496 - val_loss: 0.2591 - val_accuracy: 0.9030 - val_precision: 0.9627 - val_recall: 0.8431 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9791 - precision: 0.9805 - recall: 0.9789\n",
            "Epoch 7: val_accuracy improved from 0.90301 to 0.92642, saving model to weights-improvement-07-0.93.hdf5\n",
            "38/38 [==============================] - 19s 505ms/step - loss: 0.0690 - accuracy: 0.9791 - precision: 0.9805 - recall: 0.9789 - val_loss: 0.1828 - val_accuracy: 0.9264 - val_precision: 0.9281 - val_recall: 0.9281 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9925 - precision: 0.9951 - recall: 0.9902\n",
            "Epoch 8: val_accuracy did not improve from 0.92642\n",
            "38/38 [==============================] - 18s 467ms/step - loss: 0.0362 - accuracy: 0.9925 - precision: 0.9951 - recall: 0.9902 - val_loss: 0.1691 - val_accuracy: 0.9264 - val_precision: 0.9068 - val_recall: 0.9542 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9925 - precision: 0.9919 - recall: 0.9935\n",
            "Epoch 9: val_accuracy improved from 0.92642 to 0.92977, saving model to weights-improvement-09-0.93.hdf5\n",
            "38/38 [==============================] - 19s 506ms/step - loss: 0.0320 - accuracy: 0.9925 - precision: 0.9919 - recall: 0.9935 - val_loss: 0.1990 - val_accuracy: 0.9298 - val_precision: 0.8976 - val_recall: 0.9739 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9916 - precision: 0.9903 - recall: 0.9935\n",
            "Epoch 10: val_accuracy improved from 0.92977 to 0.94649, saving model to weights-improvement-10-0.95.hdf5\n",
            "38/38 [==============================] - 19s 512ms/step - loss: 0.0273 - accuracy: 0.9916 - precision: 0.9903 - recall: 0.9935 - val_loss: 0.1578 - val_accuracy: 0.9465 - val_precision: 0.9477 - val_recall: 0.9477 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 11: val_accuracy improved from 0.94649 to 0.95652, saving model to weights-improvement-11-0.96.hdf5\n",
            "38/38 [==============================] - 19s 506ms/step - loss: 0.0048 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1454 - val_accuracy: 0.9565 - val_precision: 0.9667 - val_recall: 0.9477 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 17s 459ms/step - loss: 0.0018 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9565 - val_precision: 0.9667 - val_recall: 0.9477 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 464ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9532 - val_precision: 0.9664 - val_recall: 0.9412 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 7.2996e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 17s 463ms/step - loss: 7.2996e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.8481e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 17s 461ms/step - loss: 5.8481e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.6850e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 17s 461ms/step - loss: 5.6850e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5881e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 480ms/step - loss: 5.5881e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-05\n",
            "Epoch 18/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5752e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 464ms/step - loss: 5.5752e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-05\n",
            "Epoch 19/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5638e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 17s 462ms/step - loss: 5.5638e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-06\n",
            "Epoch 20/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5624e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 17s 462ms/step - loss: 5.5624e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-06\n",
            "Epoch 21/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5614e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 17s 462ms/step - loss: 5.5614e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-07\n",
            "Epoch 22/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5613e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 465ms/step - loss: 5.5613e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-07\n",
            "Epoch 23/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 463ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-08\n",
            "Epoch 24/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 468ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-08\n",
            "Epoch 25/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 464ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-09\n",
            "Epoch 26/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 463ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-09\n",
            "Epoch 27/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 464ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-10\n",
            "Epoch 28/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 17s 461ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-10\n",
            "Epoch 29/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 17s 461ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-11\n",
            "Epoch 30/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 17s 462ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-11\n",
            "Epoch 31/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 17s 463ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-12\n",
            "Epoch 32/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 464ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-12\n",
            "Epoch 33/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 486ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-13\n",
            "Epoch 34/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 466ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-13\n",
            "Epoch 35/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 467ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-14\n",
            "Epoch 36/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 467ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-14\n",
            "Epoch 37/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 465ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-15\n",
            "Epoch 38/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 462ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-15\n",
            "Epoch 39/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 17s 461ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-16\n",
            "Epoch 40/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 464ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-16\n",
            "Epoch 41/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 17s 462ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-17\n",
            "Epoch 42/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 465ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-17\n",
            "Epoch 43/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 463ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-18\n",
            "Epoch 44/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 467ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-18\n",
            "Epoch 45/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 465ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-19\n",
            "Epoch 46/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 467ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-19\n",
            "Epoch 47/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 467ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-20\n",
            "Epoch 48/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 19s 490ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-20\n",
            "Epoch 49/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 466ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-21\n",
            "Epoch 50/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.95652\n",
            "38/38 [==============================] - 18s 466ms/step - loss: 5.5612e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565 - val_precision: 0.9861 - val_recall: 0.9281 - lr: 1.0000e-21\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed55daf3a0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=METRICS)\n",
        "checkpoint_path = \"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "cp = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1, mode='max')\n",
        "csv_logger = tf.keras.callbacks.CSVLogger('logfile1.log')\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=2)\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test,y_test),callbacks=[cp, csv_logger,reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWTSC3MRk17R"
      },
      "outputs": [],
      "source": [
        "## Bert layers\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "# Neural network layers\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "l = tf.keras.layers.Dense(64, activation='relu')(l)\n",
        "#l = tf.keras.layers.Flatten()(l)  # Use tf.keras.layers.Flatten() instead of Flatten()\n",
        "#l = tf.keras.layers.Dense(3, activation='softmax')(l)  # Add missing Dense layer\n",
        "l = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(l)\n",
        "l = tf.keras.layers.Dense(128, activation='relu')(l)\n",
        "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "# Use inputs and outputs to construct a final model\n",
        "model2 = tf.keras.Model(inputs=[text_input], outputs = [l])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHNf6LqDk19g",
        "outputId": "f01d4575-f14a-4f48-d45f-c858a21d1cce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.3555 - accuracy: 0.5146 - precision: 0.5271 - recall: 0.5528\n",
            "Epoch 1: val_accuracy improved from -inf to 0.55518, saving model to weights-improvement-01-0.56.hdf5\n",
            "38/38 [==============================] - 23s 532ms/step - loss: 1.3555 - accuracy: 0.5146 - precision: 0.5271 - recall: 0.5528 - val_loss: 1.1598 - val_accuracy: 0.5552 - val_precision: 0.5368 - val_recall: 0.9542 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.0414 - accuracy: 0.6008 - precision: 0.6142 - recall: 0.6033\n",
            "Epoch 2: val_accuracy improved from 0.55518 to 0.65217, saving model to weights-improvement-02-0.65.hdf5\n",
            "38/38 [==============================] - 19s 504ms/step - loss: 1.0414 - accuracy: 0.6008 - precision: 0.6142 - recall: 0.6033 - val_loss: 0.9077 - val_accuracy: 0.6522 - val_precision: 0.7290 - val_recall: 0.5098 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.8643 - accuracy: 0.6502 - precision: 0.6667 - recall: 0.6407\n",
            "Epoch 3: val_accuracy did not improve from 0.65217\n",
            "38/38 [==============================] - 17s 445ms/step - loss: 0.8643 - accuracy: 0.6502 - precision: 0.6667 - recall: 0.6407 - val_loss: 0.7880 - val_accuracy: 0.6455 - val_precision: 0.6026 - val_recall: 0.9020 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.7776 - accuracy: 0.6326 - precision: 0.6571 - recall: 0.5984\n",
            "Epoch 4: val_accuracy improved from 0.65217 to 0.68896, saving model to weights-improvement-04-0.69.hdf5\n",
            "38/38 [==============================] - 19s 514ms/step - loss: 0.7776 - accuracy: 0.6326 - precision: 0.6571 - recall: 0.5984 - val_loss: 0.7149 - val_accuracy: 0.6890 - val_precision: 0.6546 - val_recall: 0.8301 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.6762 - precision: 0.6722 - recall: 0.7236\n",
            "Epoch 5: val_accuracy improved from 0.68896 to 0.69231, saving model to weights-improvement-05-0.69.hdf5\n",
            "38/38 [==============================] - 19s 509ms/step - loss: 0.6944 - accuracy: 0.6762 - precision: 0.6722 - recall: 0.7236 - val_loss: 0.6318 - val_accuracy: 0.6923 - val_precision: 0.6894 - val_recall: 0.7255 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.6572 - accuracy: 0.6803 - precision: 0.7161 - recall: 0.6276\n",
            "Epoch 6: val_accuracy did not improve from 0.69231\n",
            "38/38 [==============================] - 17s 456ms/step - loss: 0.6572 - accuracy: 0.6803 - precision: 0.7161 - recall: 0.6276 - val_loss: 0.6506 - val_accuracy: 0.6823 - val_precision: 0.6306 - val_recall: 0.9150 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.6297 - accuracy: 0.7004 - precision: 0.7124 - recall: 0.7008\n",
            "Epoch 7: val_accuracy improved from 0.69231 to 0.71906, saving model to weights-improvement-07-0.72.hdf5\n",
            "38/38 [==============================] - 19s 495ms/step - loss: 0.6297 - accuracy: 0.7004 - precision: 0.7124 - recall: 0.7008 - val_loss: 0.6218 - val_accuracy: 0.7191 - val_precision: 0.8710 - val_recall: 0.5294 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.6035 - accuracy: 0.6996 - precision: 0.7254 - recall: 0.6699\n",
            "Epoch 8: val_accuracy improved from 0.71906 to 0.73579, saving model to weights-improvement-08-0.74.hdf5\n",
            "38/38 [==============================] - 19s 515ms/step - loss: 0.6035 - accuracy: 0.6996 - precision: 0.7254 - recall: 0.6699 - val_loss: 0.5913 - val_accuracy: 0.7358 - val_precision: 0.7056 - val_recall: 0.8301 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5854 - accuracy: 0.7322 - precision: 0.7611 - recall: 0.6992\n",
            "Epoch 9: val_accuracy did not improve from 0.73579\n",
            "38/38 [==============================] - 17s 459ms/step - loss: 0.5854 - accuracy: 0.7322 - precision: 0.7611 - recall: 0.6992 - val_loss: 0.6303 - val_accuracy: 0.6890 - val_precision: 0.6415 - val_recall: 0.8889 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5923 - accuracy: 0.6979 - precision: 0.7301 - recall: 0.6553\n",
            "Epoch 10: val_accuracy did not improve from 0.73579\n",
            "38/38 [==============================] - 17s 460ms/step - loss: 0.5923 - accuracy: 0.6979 - precision: 0.7301 - recall: 0.6553 - val_loss: 0.5526 - val_accuracy: 0.7224 - val_precision: 0.7778 - val_recall: 0.6405 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5503 - accuracy: 0.7364 - precision: 0.7698 - recall: 0.6959\n",
            "Epoch 11: val_accuracy did not improve from 0.73579\n",
            "38/38 [==============================] - 17s 456ms/step - loss: 0.5503 - accuracy: 0.7364 - precision: 0.7698 - recall: 0.6959 - val_loss: 0.6308 - val_accuracy: 0.6990 - val_precision: 0.6493 - val_recall: 0.8954 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.7389 - precision: 0.7720 - recall: 0.6992\n",
            "Epoch 12: val_accuracy did not improve from 0.73579\n",
            "38/38 [==============================] - 17s 457ms/step - loss: 0.5408 - accuracy: 0.7389 - precision: 0.7720 - recall: 0.6992 - val_loss: 0.5346 - val_accuracy: 0.7124 - val_precision: 0.7376 - val_recall: 0.6797 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.7389 - precision: 0.7780 - recall: 0.6894\n",
            "Epoch 13: val_accuracy did not improve from 0.73579\n",
            "38/38 [==============================] - 17s 452ms/step - loss: 0.5529 - accuracy: 0.7389 - precision: 0.7780 - recall: 0.6894 - val_loss: 0.5493 - val_accuracy: 0.7258 - val_precision: 0.7205 - val_recall: 0.7582 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5455 - accuracy: 0.7314 - precision: 0.7597 - recall: 0.6992\n",
            "Epoch 14: val_accuracy improved from 0.73579 to 0.75251, saving model to weights-improvement-14-0.75.hdf5\n",
            "38/38 [==============================] - 19s 499ms/step - loss: 0.5455 - accuracy: 0.7314 - precision: 0.7597 - recall: 0.6992 - val_loss: 0.5417 - val_accuracy: 0.7525 - val_precision: 0.8496 - val_recall: 0.6275 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5121 - accuracy: 0.7665 - precision: 0.8077 - recall: 0.7171\n",
            "Epoch 15: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 455ms/step - loss: 0.5121 - accuracy: 0.7665 - precision: 0.8077 - recall: 0.7171 - val_loss: 0.5265 - val_accuracy: 0.7291 - val_precision: 0.7812 - val_recall: 0.6536 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4990 - accuracy: 0.7858 - precision: 0.8318 - recall: 0.7317\n",
            "Epoch 16: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 454ms/step - loss: 0.4990 - accuracy: 0.7858 - precision: 0.8318 - recall: 0.7317 - val_loss: 0.5250 - val_accuracy: 0.7291 - val_precision: 0.7769 - val_recall: 0.6601 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5092 - accuracy: 0.7531 - precision: 0.7920 - recall: 0.7057\n",
            "Epoch 17: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 456ms/step - loss: 0.5092 - accuracy: 0.7531 - precision: 0.7920 - recall: 0.7057 - val_loss: 0.5319 - val_accuracy: 0.7258 - val_precision: 0.7320 - val_recall: 0.7320 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5048 - accuracy: 0.7665 - precision: 0.8000 - recall: 0.7285\n",
            "Epoch 18: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 18s 471ms/step - loss: 0.5048 - accuracy: 0.7665 - precision: 0.8000 - recall: 0.7285 - val_loss: 0.5258 - val_accuracy: 0.7358 - val_precision: 0.8033 - val_recall: 0.6405 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4924 - accuracy: 0.7699 - precision: 0.8137 - recall: 0.7171\n",
            "Epoch 19: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 455ms/step - loss: 0.4924 - accuracy: 0.7699 - precision: 0.8137 - recall: 0.7171 - val_loss: 0.5234 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-05\n",
            "Epoch 20/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4970 - accuracy: 0.7707 - precision: 0.8117 - recall: 0.7220\n",
            "Epoch 20: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 457ms/step - loss: 0.4970 - accuracy: 0.7707 - precision: 0.8117 - recall: 0.7220 - val_loss: 0.5234 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-05\n",
            "Epoch 21/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5063 - accuracy: 0.7531 - precision: 0.7941 - recall: 0.7024\n",
            "Epoch 21: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 454ms/step - loss: 0.5063 - accuracy: 0.7531 - precision: 0.7941 - recall: 0.7024 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4940 - accuracy: 0.7715 - precision: 0.8087 - recall: 0.7285\n",
            "Epoch 22: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 457ms/step - loss: 0.4940 - accuracy: 0.7715 - precision: 0.8087 - recall: 0.7285 - val_loss: 0.5234 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-06\n",
            "Epoch 23/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5018 - accuracy: 0.7715 - precision: 0.8098 - recall: 0.7268\n",
            "Epoch 23: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 455ms/step - loss: 0.5018 - accuracy: 0.7715 - precision: 0.8098 - recall: 0.7268 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-06\n",
            "Epoch 24/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4996 - accuracy: 0.7715 - precision: 0.8076 - recall: 0.7301\n",
            "Epoch 24: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 457ms/step - loss: 0.4996 - accuracy: 0.7715 - precision: 0.8076 - recall: 0.7301 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-07\n",
            "Epoch 25/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4963 - accuracy: 0.7766 - precision: 0.8096 - recall: 0.7398\n",
            "Epoch 25: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 456ms/step - loss: 0.4963 - accuracy: 0.7766 - precision: 0.8096 - recall: 0.7398 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-07\n",
            "Epoch 26/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5071 - accuracy: 0.7540 - precision: 0.7801 - recall: 0.7268\n",
            "Epoch 26: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 459ms/step - loss: 0.5071 - accuracy: 0.7540 - precision: 0.7801 - recall: 0.7268 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-08\n",
            "Epoch 27/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4928 - accuracy: 0.7774 - precision: 0.8179 - recall: 0.7301\n",
            "Epoch 27: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 458ms/step - loss: 0.4928 - accuracy: 0.7774 - precision: 0.8179 - recall: 0.7301 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-08\n",
            "Epoch 28/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.7582 - precision: 0.7880 - recall: 0.7252\n",
            "Epoch 28: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 19s 507ms/step - loss: 0.5112 - accuracy: 0.7582 - precision: 0.7880 - recall: 0.7252 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-09\n",
            "Epoch 29/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.7741 - precision: 0.8000 - recall: 0.7480\n",
            "Epoch 29: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 458ms/step - loss: 0.5024 - accuracy: 0.7741 - precision: 0.8000 - recall: 0.7480 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-09\n",
            "Epoch 30/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.7732 - precision: 0.8060 - recall: 0.7366\n",
            "Epoch 30: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 456ms/step - loss: 0.5001 - accuracy: 0.7732 - precision: 0.8060 - recall: 0.7366 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-10\n",
            "Epoch 31/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5032 - accuracy: 0.7632 - precision: 0.8018 - recall: 0.7171\n",
            "Epoch 31: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 455ms/step - loss: 0.5032 - accuracy: 0.7632 - precision: 0.8018 - recall: 0.7171 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-10\n",
            "Epoch 32/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.7623 - precision: 0.7993 - recall: 0.7187\n",
            "Epoch 32: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 454ms/step - loss: 0.5050 - accuracy: 0.7623 - precision: 0.7993 - recall: 0.7187 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-11\n",
            "Epoch 33/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.7615 - precision: 0.7946 - recall: 0.7236\n",
            "Epoch 33: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 456ms/step - loss: 0.5024 - accuracy: 0.7615 - precision: 0.7946 - recall: 0.7236 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-11\n",
            "Epoch 34/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5044 - accuracy: 0.7623 - precision: 0.7971 - recall: 0.7220\n",
            "Epoch 34: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 453ms/step - loss: 0.5044 - accuracy: 0.7623 - precision: 0.7971 - recall: 0.7220 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-12\n",
            "Epoch 35/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5010 - accuracy: 0.7674 - precision: 0.8047 - recall: 0.7236\n",
            "Epoch 35: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 458ms/step - loss: 0.5010 - accuracy: 0.7674 - precision: 0.8047 - recall: 0.7236 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-12\n",
            "Epoch 36/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.7724 - precision: 0.8101 - recall: 0.7285\n",
            "Epoch 36: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 453ms/step - loss: 0.5015 - accuracy: 0.7724 - precision: 0.8101 - recall: 0.7285 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-13\n",
            "Epoch 37/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5076 - accuracy: 0.7473 - precision: 0.7770 - recall: 0.7138\n",
            "Epoch 37: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 455ms/step - loss: 0.5076 - accuracy: 0.7473 - precision: 0.7770 - recall: 0.7138 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-13\n",
            "Epoch 38/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4897 - accuracy: 0.7791 - precision: 0.8074 - recall: 0.7496\n",
            "Epoch 38: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 454ms/step - loss: 0.4897 - accuracy: 0.7791 - precision: 0.8074 - recall: 0.7496 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-14\n",
            "Epoch 39/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.7623 - precision: 0.7950 - recall: 0.7252\n",
            "Epoch 39: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 18s 471ms/step - loss: 0.5080 - accuracy: 0.7623 - precision: 0.7950 - recall: 0.7252 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-14\n",
            "Epoch 40/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5025 - accuracy: 0.7724 - precision: 0.8101 - recall: 0.7285\n",
            "Epoch 40: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 453ms/step - loss: 0.5025 - accuracy: 0.7724 - precision: 0.8101 - recall: 0.7285 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-15\n",
            "Epoch 41/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4913 - accuracy: 0.7841 - precision: 0.8205 - recall: 0.7431\n",
            "Epoch 41: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 455ms/step - loss: 0.4913 - accuracy: 0.7841 - precision: 0.8205 - recall: 0.7431 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-15\n",
            "Epoch 42/50\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5002 - accuracy: 0.7707 - precision: 0.8072 - recall: 0.7285\n",
            "Epoch 42: val_accuracy did not improve from 0.75251\n",
            "38/38 [==============================] - 17s 452ms/step - loss: 0.5002 - accuracy: 0.7707 - precision: 0.8072 - recall: 0.7285 - val_loss: 0.5233 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.6601 - lr: 1.0000e-16\n",
            "Epoch 43/50\n",
            "35/38 [==========================>...] - ETA: 1s - loss: 0.4921 - accuracy: 0.7723 - precision: 0.8075 - recall: 0.7236"
          ]
        }
      ],
      "source": [
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model2.compile(optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=METRICS)\n",
        "checkpoint_path = \"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "cp = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1, mode='max')\n",
        "csv_logger = tf.keras.callbacks.CSVLogger('logfile2.log')\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=2)\n",
        "model2.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test,y_test),callbacks=[cp, csv_logger,reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ8hfIBVk2By",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68c6446f-324b-4ffa-d8a9-f7c143cef3a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Accuracy: 0.9498327759197325\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Obtain predictions from Model 1 and Model 2\n",
        "predictions_model = model.predict(X_test)\n",
        "predictions_model2 = model2.predict(X_test)\n",
        "\n",
        "# Perform averaging\n",
        "ensemble_predictions = np.round((predictions_model + predictions_model2) / 2)\n",
        "\n",
        "# Evaluate the performance of the ensemble\n",
        "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
        "print(f\"Ensemble Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "sample_dataset = [\n",
        "\" the scene is in the in the kitchen . the mother is wiping dishes and the water is running on the floor . a child is trying to get a boy is trying to get cookies outta out a jar and he's about to tip over on a stool . the little girl is reacting to his falling . it seems to be summer out . the window is open . the curtains are blowing . it must be a gentle breeze . there's grass outside in the garden . mother's finished certain of the the dishes . kitchen's very tidy . the mother seems to have nothing in the house to eat except cookies in the cookie jar . the children look to be almost about the same size . perhaps they're twins . they're dressed for summer warm weather . you want more ? the mother's in a short sleeve dress . I'll hafta say it's warm . \" ,\n",
        "                   \"  it's kinda shiny there . I   okay it looks like somebody's raiding the cookie jar .  there's a woman  working in the kitchen .  and there's this little girl here with something but I don't know what it is she yeah I'm trying to identify this thing . d?d?ku trying to see . is that a table leg ?  I'd say that's a table leg . \",\n",
        "                  \"the little boy is reaching for a cookie . and he's falling at the same time because the stool has tipped over . his little sister is reaching for a cookie and I think beginning to laugh because he's falling . the sink is running over and dripping water on the floor while the mother is trying to dry the dishes . the window is open and the curtains are blowing in the breeze coming in from outside . the water is running in the sink . that's why it's overflowing .  I also believe that the mother is daydreaming .  possibly worrying about something . that's it . that's all I see . \" ]\n",
        "\n",
        "# Make predictions using the ensemble model\n",
        "ensemble_predictions = np.round((model.predict(sample_dataset) + model2.predict(sample_dataset)) / 2)\n",
        "\n",
        "# Display the predictions\n",
        "print(\"Ensemble Predictions:\")\n",
        "for prediction in ensemble_predictions:\n",
        "    print(prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PGVmgQ8np83",
        "outputId": "15466835-7a99-428c-a398-8a15edbac312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Predictions:\n",
            "[0.]\n",
            "[1.]\n",
            "[0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_model = model.predict(X_test)\n",
        "predictions_model2 = model2.predict(X_test)"
      ],
      "metadata": {
        "id": "cXz3EOizc1qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W4IMBfOk2EO"
      },
      "outputs": [],
      "source": [
        "y_predicted_model = model.predict(X_test)\n",
        "y_predicted_model2 = model2.predict(X_test)\n",
        "y_predicted_model = y_predicted_model.flatten()\n",
        "y_predicted_model2 = y_predicted_model2.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_dataset = [\n",
        "\" the scene is in the in the kitchen . the mother is wiping dishes and the water is running on the floor . a child is trying to get a boy is trying to get cookies outta out a jar and he's about to tip over on a stool . the little girl is reacting to his falling . it seems to be summer out . the window is open . the curtains are blowing . it must be a gentle breeze . there's grass outside in the garden . mother's finished certain of the the dishes . kitchen's very tidy . the mother seems to have nothing in the house to eat except cookies in the cookie jar . the children look to be almost about the same size . perhaps they're twins . they're dressed for summer warm weather . you want more ? the mother's in a short sleeve dress . I'll hafta say it's warm . \" ,\n",
        "                   \"  it's kinda shiny there . I   okay it looks like somebody's raiding the cookie jar .  there's a woman  working in the kitchen .  and there's this little girl here with something but I don't know what it is she yeah I'm trying to identify this thing . d?d?ku trying to see . is that a table leg ?  I'd say that's a table leg . \",\n",
        "                  \"the little boy is reaching for a cookie . and he's falling at the same time because the stool has tipped over . his little sister is reaching for a cookie and I think beginning to laugh because he's falling . the sink is running over and dripping water on the floor while the mother is trying to dry the dishes . the window is open and the curtains are blowing in the breeze coming in from outside . the water is running in the sink . that's why it's overflowing .  I also believe that the mother is daydreaming .  possibly worrying about something . that's it . that's all I see . \" ]\n",
        "model.predict(sample_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6x6ctkdmZ-C",
        "outputId": "87f58e60-6c41-4c4d-d738-9653a2c23589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11824717],\n",
              "       [0.501327  ],\n",
              "       [0.06559467]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_dataset = [\n",
        "\" the scene is in the in the kitchen . the mother is wiping dishes and the water is running on the floor . a child is trying to get a boy is trying to get cookies outta out a jar and he's about to tip over on a stool . the little girl is reacting to his falling . it seems to be summer out . the window is open . the curtains are blowing . it must be a gentle breeze . there's grass outside in the garden . mother's finished certain of the the dishes . kitchen's very tidy . the mother seems to have nothing in the house to eat except cookies in the cookie jar . the children look to be almost about the same size . perhaps they're twins . they're dressed for summer warm weather . you want more ? the mother's in a short sleeve dress . I'll hafta say it's warm . \" ,\n",
        "                   \"  it's kinda shiny there . I   okay it looks like somebody's raiding the cookie jar .  there's a woman  working in the kitchen .  and there's this little girl here with something but I don't know what it is she yeah I'm trying to identify this thing . d?d?ku trying to see . is that a table leg ?  I'd say that's a table leg . \",\n",
        "                  \"the little boy is reaching for a cookie . and he's falling at the same time because the stool has tipped over . his little sister is reaching for a cookie and I think beginning to laugh because he's falling . the sink is running over and dripping water on the floor while the mother is trying to dry the dishes . the window is open and the curtains are blowing in the breeze coming in from outside . the water is running in the sink . that's why it's overflowing .  I also believe that the mother is daydreaming .  possibly worrying about something . that's it . that's all I see . \" ]\n",
        "model2.predict(sample_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcDwL-A9oAwL",
        "outputId": "7b0a6943-58ec-4e7c-ee22-b1365919dbba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11824717],\n",
              "       [0.501327  ],\n",
              "       [0.06559467]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}